from __future__ import annotations

from typing import Any, Dict, Optional, TypedDict, List, Tuple
from datetime import datetime, timezone
import os
import re
import requests
try:
    from pg_logger import log_tool_call
except Exception:
    def log_tool_call(**kwargs):
        return


# ============================
# STATE MODEL
# ============================

class BrainState(TypedDict, total=False):
    text: str
    user_id: str

    context: str
    used_context: bool
    num_docs: int

    used_conversation_context: bool
    conversation_context: str

    target_expert: str
    answer: str

    tool: Optional[str]
    tool_args: Dict[str, Any]
    tool_result: Any
    tool_error: Optional[str]


# ============================
# SMALL UTILS
# ============================

def utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

def clamp_text(s: str, max_chars: int = 2500) -> str:
    s = (s or "").strip()
    if len(s) <= max_chars:
        return s
    return s[: max_chars - 20] + "\n...[truncated]..."


# ============================
# POLICY B — CONVERSATION MEMORY INJECTION (heuristic gate)
# ============================

_CONVO_HINT_PATTERNS = [
    r"\bremember\b",
    r"\byou said\b",
    r"\blast time\b",
    r"\bearlier\b",
    r"\bprevious(ly)?\b",
    r"\bwe talked\b",
    r"\bwhat did i say\b",
    r"\bmy favorite\b",
    r"\bmy preference\b",
    r"\bfrom now on\b",
    r"\bgoing forward\b",
    r"\bdon't forget\b",
]

def conversation_relevance_heuristic(query: str) -> bool:
    q = (query or "").strip().lower()
    if not q:
        return False
    for pat in _CONVO_HINT_PATTERNS:
        if re.search(pat, q):
            return True
    if len(q) <= 18 and any(w in q for w in ["favorite", "prefer", "like", "hate"]):
        return True
    return False

def retrieve_conversation_context_if_relevant(
    *,
    conv_store,
    user_id: str,
    query_text: str,
    k: int = 6,
    score_threshold: float = 0.28,
) -> Tuple[str, bool]:
    if not conversation_relevance_heuristic(query_text):
        return "", False
    try:
        q = f"user_id={user_id}\n{query_text}"
        docs = conv_store.similarity_search_with_score(q, k=k)
        kept: List[str] = []
        for d, score in docs:
            if score is None:
                continue
            if score >= score_threshold:
                kept.append(d.page_content)
        if not kept:
            return "", False
        return clamp_text("\n---\n".join(kept), 2500), True
    except Exception as e:
        print(f"[Delilah Brain] conversation_memory retrieval warning: {e}", flush=True)
        return "", False


# ============================
# ROUTER HINTS (default general)
# ============================

def router_hint_target(*, router_store, user_id: str, query_text: str) -> str:
    default = "general"
    try:
        q = f"user_id={user_id}\n{query_text}"
        docs = router_store.similarity_search(q, k=3)
        for d in docs:
            meta = getattr(d, "metadata", {}) or {}
            tgt = meta.get("target_expert")
            if tgt:
                return str(tgt)
        return default
    except Exception as e:
        print(f"[Delilah Brain] router_hints warning: {e}", flush=True)
        return default


# ============================
# PERSONA MEMORY (kept separate, lightweight)
# ============================

def persona_directives(*, persona_store, user_id: str, k: int = 4) -> str:
    try:
        q = f"user_id={user_id}\npersona directives"
        docs = persona_store.similarity_search(q, k=k)
        if not docs:
            return ""
        lines: List[str] = []
        for d in docs:
            txt = (d.page_content or "").strip()
            if txt:
                lines.append(txt)
        return clamp_text("\n".join(lines), 1200)
    except Exception as e:
        print(f"[Delilah Brain] persona_memory warning: {e}", flush=True)
        return ""


# ============================
# WEATHER TOOL (NWS + OSM)
# ============================

DEFAULT_LOCATION_QUERY = "Rockford, MI 49341"

def _ua() -> str:
    return os.getenv("DELILAH_UA", "delilah-server (ryan.j.werner80@gmail.com)")

def geocode_location_osm(location_name: str) -> Optional[Dict[str, Any]]:
    try:
        url = "https://nominatim.openstreetmap.org/search"
        params = {"q": location_name, "format": "json", "limit": 1}
        r = requests.get(url, params=params, headers={"User-Agent": _ua()}, timeout=10)
        r.raise_for_status()
        data = r.json()
        if not data:
            return None
        return {
            "lat": float(data[0]["lat"]),
            "lon": float(data[0]["lon"]),
            "label": data[0].get("display_name", location_name),
        }
    except Exception as e:
        print(f"[Tool] OSM geocode failed: {e}", flush=True)
        return None

def nws_points(lat: float, lon: float) -> Optional[Dict[str, Any]]:
    try:
        url = f"https://api.weather.gov/points/{lat:.4f},{lon:.4f}"
        r = requests.get(url, headers={"User-Agent": _ua(), "Accept": "application/geo+json"}, timeout=12)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        print(f"[Tool] NWS points failed: {e}", flush=True)
        return None

def nws_forecast(forecast_url: str) -> Optional[Dict[str, Any]]:
    try:
        r = requests.get(forecast_url, headers={"User-Agent": _ua(), "Accept": "application/geo+json"}, timeout=12)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        print(f"[Tool] NWS forecast failed: {e}", flush=True)
        return None

def weather_tool(tool_args: Dict[str, Any]) -> Dict[str, Any]:
    location_name = (tool_args.get("location_name") or "").strip() or DEFAULT_LOCATION_QUERY
    detail_level = (tool_args.get("detail_level") or "short").strip().lower()

    geo = geocode_location_osm(location_name)
    if not geo:
        return {"ok": False, "error": f"Could not resolve location '{location_name}'."}

    pts = nws_points(geo["lat"], geo["lon"])
    if not pts:
        return {"ok": False, "error": "Weather.gov points lookup failed."}

    props = (pts.get("properties") or {})
    forecast_url = props.get("forecast")
    if not forecast_url:
        return {"ok": False, "error": "Weather.gov did not return a forecast URL."}

    fc = nws_forecast(forecast_url)
    if not fc:
        return {"ok": False, "error": "Weather.gov forecast lookup failed."}

    periods = (fc.get("properties") or {}).get("periods") or []
    if not periods:
        return {"ok": False, "error": "Weather.gov forecast returned no periods."}

    nowp = periods[0]
    nextp = periods[1] if len(periods) > 1 else None

    now_line = f"{nowp.get('name','Now')}: {nowp.get('temperature')}°{nowp.get('temperatureUnit','F')} — {nowp.get('shortForecast','')}".strip()
    if detail_level == "short":
        if nextp:
            nxt = f"{nextp.get('name','Next')}: {nextp.get('shortForecast','')}".strip()
            summary = f"{now_line}. {nxt}"
        else:
            summary = now_line
    else:
        summary = nowp.get("detailedForecast") or now_line

    return {
        "ok": True,
        "summary": summary,
        "detail_level": detail_level,
        "location_name": location_name if tool_args.get("location_name") else None,
        "source": "National Weather Service (weather.gov)",
    }

def detect_weather_intent(lower_text: str) -> bool:
    return any(w in lower_text for w in ["weather", "forecast", "temperature", "temp", "rain", "snow", "wind"])

def parse_weather_args(query_text: str) -> Dict[str, Any]:
    lower = (query_text or "").strip().lower()
    cleaned = re.sub(r"\bright now\b", "", lower, flags=re.IGNORECASE).strip()
    args: Dict[str, Any] = {"detail_level": "short"}
    m = re.search(r"\bweather in (.+)$", cleaned)
    if m:
        loc = m.group(1).strip(" .?!")
        if loc:
            args["location_name"] = loc
    return args


# ============================
# GRAPH (minimal, stable)
# ============================

def build_simple_graph(*, llm, vector_store, conv_store, persona_store, router_store):
    class _Graph:
        def invoke(self, state: BrainState) -> BrainState:
            text = (state.get("text") or "").strip()
            user_id = (state.get("user_id") or "").strip() or "ryan"
            lower = text.lower()

            state["tool"] = None
            state["tool_args"] = {}
            state["tool_result"] = None
            state["tool_error"] = None

            state["target_expert"] = router_hint_target(router_store=router_store, user_id=user_id, query_text=text)

            persona = persona_directives(persona_store=persona_store, user_id=user_id)

            convo_ctx, used_convo = retrieve_conversation_context_if_relevant(
                conv_store=conv_store, user_id=user_id, query_text=text
            )
            state["conversation_context"] = convo_ctx
            state["used_conversation_context"] = bool(used_convo)

            docs = []
            try:
                docs = vector_store.similarity_search(text, k=3)
            except Exception as e:
                print(f"[Delilah Brain] delilah_knowledge retrieval warning: {e}", flush=True)
                docs = []
            rag_ctx = "\n\n".join(d.page_content for d in docs) if docs else ""

            tool_block = ""
            if detect_weather_intent(lower):
                state["tool"] = "weather"
                state["tool_args"] = parse_weather_args(text)
                try:
                    started_at = datetime.now(timezone.utc)
state["tool_result"] = weather_tool(state["tool_args"])
ended_at = datetime.now(timezone.utc)
log_tool_call(
    trace_id=state.get('trace_id'),
    user_id=state.get('user_id'),
    tool='weather',
    args=state.get('tool_args'),
    result=state.get('tool_result'),
    started_at=started_at,
    ended_at=ended_at,
)
                except Exception as e:
                    state["tool_error"] = str(e)
                    state["tool_result"] = {"ok": False, "error": str(e)}

                tr = state.get("tool_result") if isinstance(state.get("tool_result"), dict) else {}
                if tr and tr.get("ok"):
                    tool_block = f"TOOL RESULT (Weather) [{tr.get('source','weather.gov')}]: {tr.get('summary','')}".strip()

            ctx_parts: List[str] = []
            if used_convo and convo_ctx:
                ctx_parts.append("CONVERSATION MEMORY (relevant excerpts):\n" + convo_ctx)
            if rag_ctx:
                ctx_parts.append("KNOWLEDGE BASE (RAG):\n" + rag_ctx)
            if tool_block:
                ctx_parts.append(tool_block)
            context = "\n\n".join(ctx_parts).strip()

            state["context"] = context
            state["used_context"] = bool(context)
            state["num_docs"] = len(docs)

            system_rules = [
                "You are Delilah, Ryan's local-first assistant.",
                "Do not assume the user wants coding help unless explicitly requested.",
                "Use conversation memory only when it is likely relevant (Policy B).",
                "Do not merge persona memory with conversation memory.",
                "If you used a tool, refer to it by its concrete name (National Weather Service / weather.gov).",
                "Keep responses concise unless the user asks for depth.",
            ]
            if persona:
                system_rules.append("PERSONA DIRECTIVES:\n" + persona)

            prompt = (
                "SYSTEM:\n" + "\n".join(f"- {r}" for r in system_rules)
                + "\n\n"
                + (f"CONTEXT:\n{context}\n\n" if context else "")
                + f"USER:\n{text}\n\nASSISTANT:"
            )

            try:
                answer = llm.invoke(prompt)
            except Exception as e:
                answer = f"I ran into an internal error generating a response: {e}"

            state["answer"] = (answer or "").strip()
            return state

    return _Graph()
